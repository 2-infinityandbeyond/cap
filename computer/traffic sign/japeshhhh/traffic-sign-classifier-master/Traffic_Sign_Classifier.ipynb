{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "### Author: Sergey Morozov\n",
    "\n",
    "In this notebook, a traffic sign classifier is implemented. [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset) is used to train the model. There is a [write-up](./Writeup.md) where different stages of the implementation are described including analysis of the pros and cons of the chosen approaches and suggestions for further improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, 'v'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-77a04b7b68b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, 'v'."
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Data's location\n",
    "training_file = \"traffic-sign-data/train.p\"\n",
    "validation_file = \"traffic-sign-data/valid.p\"\n",
    "testing_file = \"traffic-sign-data/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "# features and labels\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "# Sign id<->name mapping\n",
    "sign_names = pd.read_csv('signnames.csv').to_dict(orient='index')\n",
    "sign_names = { key : val['SignName'] for key, val in sign_names.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Basic Summary of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# Number of validation examples.\n",
    "n_valid = len(X_valid)\n",
    "\n",
    "# What's the shape of an traffic sign image?\n",
    "image_shape = X_train.shape[1:]\n",
    "\n",
    "# How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Number of validation examples =\", n_valid)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Exploratory Visualization of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Samples in Each Category\n",
    "The categories with minimum/maximum number of samples are marked with yellow/red color correspondingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "samples_per_category = [len(np.where(y_train==cat_id)[0]) for cat_id in sign_names.keys()]\n",
    "category_names = tuple([val + \" [ id:{id} ]\".format(id=key) for key,val in sign_names.items()])\n",
    "\n",
    "min_cnt = min(samples_per_category)\n",
    "max_cnt = max(samples_per_category)\n",
    "\n",
    "y_pos = np.arange(len(category_names))\n",
    "\n",
    "rects = ax.barh(y_pos, \n",
    "                samples_per_category, \n",
    "                align='center', \n",
    "                color=['green' if val != min_cnt and val != max_cnt \\\n",
    "                       else 'yellow' if val == min_cnt \\\n",
    "                       else 'red' for val in samples_per_category])\n",
    "\n",
    "# setting labels for each bar\n",
    "for i in range(0,len(rects)):\n",
    "    ax.text(int(rects[i].get_width()), \n",
    "            int(rects[i].get_y()+rects[i].get_height()/2.0),\n",
    "            samples_per_category[i],\n",
    "            fontproperties=fm.FontProperties(size=5))\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(category_names,fontproperties=fm.FontProperties(size=5))\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Samples per Category')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Image from Each Category\n",
    "\n",
    "Output a sample image from each category. Note, that images will be transformed before they are passed to neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "h_or_w = image_shape[0]\n",
    "fig = plt.figure(figsize=(h_or_w,h_or_w))\n",
    "for i in range(0, n_classes):\n",
    "    samples = np.where(y_train==i)[0]\n",
    "    index = random.randint(0, len(samples) - 1)\n",
    "    image = X_train[samples[index]]\n",
    "    \n",
    "    ax = fig.add_subplot(math.ceil(n_classes/5), 5, i+1)\n",
    "    ax.set_title(sign_names[i])\n",
    "    ax.set_ylabel(\"id: {id}\".format(id=i))\n",
    "    plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. The LeNet-5 CNN architecture is used here with minor modifications: dropout parameter added to the first fully connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def prepare_image(image_set):\n",
    "    \"\"\"Transform initial set of images so that they are ready to be fed to neural network.\n",
    "    \n",
    "    (1) normalize image\n",
    "    (2) convert RGB image to gray scale\n",
    "    \"\"\"\n",
    "    # initialize empty image set for prepared images\n",
    "    new_shape = image_shape[0:2] + (1,)\n",
    "    \n",
    "    prep_image_set = np.empty(shape=(len(image_set),) + new_shape, dtype=int)\n",
    "    \n",
    "    for ind in range(0, len(image_set)):\n",
    "        # normalize\n",
    "        norm_img = cv2.normalize(image_set[ind], np.zeros(image_shape[0:2]), 0, 255, cv2.NORM_MINMAX)\n",
    "        \n",
    "        # grayscale\n",
    "        gray_img = cv2.cvtColor(norm_img, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # set new image to the corresponding position\n",
    "        prep_image_set[ind] = np.reshape(gray_img, new_shape)\n",
    "        \n",
    "    return prep_image_set\n",
    "        \n",
    "def equalize_number_of_samples(image_set, image_labels):\n",
    "    \"\"\"Make number of samples in each category equal.\n",
    "    \n",
    "    The data set has different number of samples for each category.\n",
    "    This function will transform the data set in a way that each category \n",
    "    will contain the number of samples equal to maximum samples per category\n",
    "    from the initial set. This will provide an equal probability to meet \n",
    "    traffic sign of each category during the training process.\n",
    "    \"\"\"\n",
    "    num = max([len(np.where(image_labels==cat_id)[0]) for cat_id in sign_names.keys()])\n",
    "    \n",
    "    equalized_image_set = np.empty(shape=(num * n_classes,) + image_set.shape[1:], dtype=int)\n",
    "    equalized_image_labels = np.empty(shape=(num * n_classes,), dtype=int)\n",
    "    j = 0\n",
    "    \n",
    "    for cat_id in sign_names.keys():\n",
    "        cat_inds = np.where(y_train==cat_id)[0]\n",
    "        cat_inds_len = len(cat_inds)\n",
    "    \n",
    "        for i in range(0, num):\n",
    "            equalized_image_set[j] = image_set[cat_inds[i % cat_inds_len]]\n",
    "            equalized_image_labels[j] = image_labels[cat_inds[i % cat_inds_len]]\n",
    "            j += 1\n",
    "    \n",
    "    # at this stage data is definitely not randomly shuffled, so shuffle it\n",
    "    return shuffle(equalized_image_set, equalized_image_labels)\n",
    "\n",
    "X_train_prep = prepare_image(X_train)\n",
    "X_test_prep = prepare_image(X_test)\n",
    "X_valid_prep = prepare_image(X_valid)\n",
    "\n",
    "X_train_prep, y_train_prep = equalize_number_of_samples(X_train_prep, y_train)\n",
    "# we do not need to transform labes for validation and test sets\n",
    "y_test_prep = y_test\n",
    "y_valid_prep = y_valid\n",
    "\n",
    "image_shape_prep = X_train_prep[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LeNet-5 architecture is used.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x, channels, classes, keep_prob, mu=0, sigma=0.01):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables \n",
    "    # for the weights and biases for each layer\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 32x32xchannels. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, channels, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # Layer 1: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # Layer 1: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # Layer 2: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # Layer 2: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 2: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0   = flatten(conv2)\n",
    "    fc0   = tf.nn.dropout(fc0, keep_prob=keep_prob)\n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # Layer 3: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # Layer 4: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, classes), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(classes))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x is a placeholder for a batch of input images\n",
    "x = tf.placeholder(tf.float32, (None,) + image_shape_prep)\n",
    "\n",
    "# y is a placeholder for a batch of output labels\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters of the training process\n",
    "RATE = 0.0008\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "KEEP_PROB = 0.7\n",
    "STDDEV = 0.01\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "logits = LeNet(x, image_shape_prep[-1], n_classes, keep_prob, sigma=STDDEV)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = RATE)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train_prep)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train_prep, y_train_prep = shuffle(X_train_prep, y_train_prep)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train_prep[offset:end], y_train_prep[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: KEEP_PROB})\n",
    "            \n",
    "        train_accuracy = evaluate(X_train_prep, y_train_prep)    \n",
    "        validation_accuracy = evaluate(X_valid_prep, y_valid_prep)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Train Accuracy = {:.3f}\".format(train_accuracy))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './model.ckpt')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Trained Model Using Test Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model.ckpt')\n",
    "\n",
    "    test_accuracy = evaluate(X_test_prep, y_test_prep)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "It is time to apply the trained model to the German trafic sign images that were obtained from the Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img_paths = os.listdir(\"traffic-sign-images\")\n",
    "images = list()\n",
    "labels = list()\n",
    "\n",
    "# read images and resize\n",
    "for img_path in img_paths:\n",
    "    # read image from file\n",
    "    img = mpimg.imread(os.path.join(\"traffic-sign-images\", img_path))\n",
    "    img = cv2.resize(img, image_shape[0:2], interpolation=cv2.INTER_CUBIC)\n",
    "    images.append(img)\n",
    "    \n",
    "    # prefix of each image name is a number of its category\n",
    "    labels.append(int(img_path[0:img_path.find('-')]))\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "    \n",
    "    \n",
    "# output the resized images\n",
    "h_or_w = image_shape[0]\n",
    "fig = plt.figure(figsize=(h_or_w,h_or_w))\n",
    "for i in range(0, len(images)):\n",
    "    ax = fig.add_subplot(1, len(images), i+1)\n",
    "    ax.set_title(sign_names[labels[i]])\n",
    "    ax.set_ylabel(\"id: {id}\".format(id=labels[i]))\n",
    "    plt.imshow(images[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess images first\n",
    "images_prep = prepare_image(images)\n",
    "labels_prep = labels\n",
    "\n",
    "# then make a prediction\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model.ckpt')\n",
    "    sign_ids = sess.run(tf.argmax(logits, 1), feed_dict={x: images_prep, y: labels_prep, keep_prob: 1})\n",
    "\n",
    "# output the results in the table\n",
    "print('-' * 93)\n",
    "print(\"| {p:^43} | {a:^43} |\".format(p='PREDICTED', a='ACTUAL'))\n",
    "print('-' * 93)\n",
    "for i in range(len(sign_ids)):\n",
    "    print('| {p:^2} {strp:^40} | {a:^2} {stra:^40} |'.format(\n",
    "        p=sign_ids[i], strp=sign_names[sign_ids[i]], a=labels[i], stra=sign_names[labels[i]]))\n",
    "print('-' * 93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run evaluation on the new images\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model.ckpt')\n",
    "\n",
    "    test_accuracy = evaluate(images_prep, labels_prep)\n",
    "    print(\"Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print out the top five softmax probabilities for the predictions on \n",
    "# the German traffic sign images found on the web. \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model.ckpt')\n",
    "    top_k = sess.run(tf.nn.top_k(tf.nn.softmax(logits), k=5), \n",
    "                     feed_dict={x: images_prep, y: labels_prep, keep_prob: 1})\n",
    "print(top_k)\n",
    "\n",
    "plt.rcdefaults()\n",
    "\n",
    "# show histogram of top 5 softmax probabilities for each image\n",
    "h_or_w = image_shape[0]\n",
    "fig = plt.figure()\n",
    "for i in range(0, len(images)):\n",
    "    ax = fig.add_subplot(len(images), 1, i+1)\n",
    "    probabilities = top_k.values[i]\n",
    "    y_pos = np.arange(len(probabilities))\n",
    "    ax.set_ylabel(\"actual id: {id}\".format(id=labels[i]), fontproperties=fm.FontProperties(size=5))\n",
    "    rects = ax.barh(y_pos, \n",
    "                probabilities, \n",
    "                align='center', \n",
    "                color='blue')\n",
    "    # setting labels for each bar\n",
    "    for j in range(0,len(rects)):\n",
    "        ax.text(int(rects[j].get_width()), \n",
    "                int(rects[j].get_y()+rects[j].get_height()/2.0),\n",
    "                probabilities[j],\n",
    "                fontproperties=fm.FontProperties(size=5), color='red')\n",
    "\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(top_k.indices[i], fontproperties=fm.FontProperties(size=5))\n",
    "    \n",
    "    xticks = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticks, fontproperties=fm.FontProperties(size=5))\n",
    "    ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
